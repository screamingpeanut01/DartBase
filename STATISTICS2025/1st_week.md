# 1st_week

# 통계학 1주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_1st_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

1주차는 `1부. 데이터 기초체력 기르기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.

## Study Schedule

| 주차 | 공부 범위 | 완료 여부 |
| --- | --- | --- |
| 1주차 | 1부 p.2~56 | ✅ |
| 2주차 | 1부 p.57~79 | 🍽️ |
| 3주차 | 2부 p.82~120 | 🍽️ |
| 4주차 | 2부 p.121~202 | 🍽️ |
| 5주차 | 2부 p.203~254 | 🍽️ |
| 6주차 | 3부 p.300~356 | 🍽️ |
| 7주차 | 3부 p.357~615 | 🍽️ |

## Statistics_1st_TIL

### 1부. 데이터 기초체력 기르기

### 01. 통계학 이해하기

### 1.1 통계학을 알아야 하는 이유

- 현대 사회는 데이터 중심
- 통계학은 데이터를 올바르게 수집·분석·해석하여 비즈니스, 정책 결정 등 모든 분야에서 객관적이고 신뢰할 수 있는 결론을 얻는 데 필수적
- 머신러닝·딥러닝의 기초는 통계학에 기반

### 1.2 머신러닝과 전통적 통계학의 차이

- **목적과 접근방식의 차이**
    - 전통적 통계학은 데이터의 원리를 설명하고 가설을 검정하여 해석하는 데 중점
    - 머신러닝은 대규모 데이터를 활용하여 높은 예측 정확도와 분류 성능을 얻는 데 초점
- **변수의 수와 모델의 복잡성**
    - 통계학 모델은 소수의 변수를 사용하여 모델의 간결성과 해석 가능성을 중요시
    - 머신러닝 모델은 수십에서 수천 개의 변수를 활용하여 복잡하지만 정확한 예측을 추구
- **가설 설정 방법**
    - 전통적 통계학은 미리 설정한 가설을 데이터로 검정하는 하향식(top-down) 접근
    - 머신러닝은 데이터 자체로부터 가설을 도출하고 이를 검증하는 상향식(bottom-up) 접근

### 1.3 통계학의 정의와 기원

- 자료 수집·분석을 통해 현상을 이해하고, 효율적인 의사결정을 내리는 학문
- **기원과 발전**
    - 고대 이집트, 로마에서 인구조사로 출발하여 근대 영국, 독일, 프랑스를 중심으로 발전
    - 영국에서는 존 그랜트가 최초의 체계적 인구 통계를 만들었고, 골턴이 회귀분석, 피어슨이 상관계수를 창안
    - 독일은 콘링이 국가 통계를, 프랑스는 라플라스와 베르누이가 확률론 기반
- **현대 통계학의 기여자들**
    - Francis Galton: 회귀분석과 상관계수 개념을 최초 제안
    - Karl Pearson: 통계학의 아버지로 불리며, 현대적 통계학의 기반을 구축
    - John Tukey: 탐색적 데이터 분석(EDA)을 창시하여 현대 데이터 과학 발전에 기여

### 1.4 기술통계와 추론통계

- **기술통계Descriptive Statistics**
    - 데이터의 특징을 묘사하고 요약
    - 대표값(평균, 중앙값, 최빈값), 산포도(분산, 표준편차, 범위), 왜도, 첨도 등 포함
    - 시각화 도구(히스토그램, 산점도, 박스 플롯)를 통해 데이터를 직관적으로 전달
- **추론통계Inferential Statistics**
    - 표본 데이터를 기반으로 모집단population의 특성을 추정하거나 검정
    - 신뢰구간 추정, 가설검정 등을 포함하여 모집단의 일반화를 시도
    - 여론조사에서 신뢰구간과 p-value 활용해 모집단의 지지율 등을 추론

### 02. 모집단과 표본추출

### 2.1 모집단과 표본의 정의 및 중요성

- 모집단population은 연구나 분석의 전체 대상이며, 이론적으로 완전한 데이터 모두 포함하는 집합
- 표본sample은 모집단에서 일부를 추출하여 분석하는 데이터로 실제 분석을 수행하는 대상
- 전수조사는 정확하지만 현실적으로는 불가능하거나 비용·시간이 과도하여 표본조사가 일반적으로 활용

### 2.2 전수조사와 표본조사의 차이점과 예시

- **전수조사**는 인구조사, 선거 투표처럼 모든 구성원을 포함하여 실시되는 조사로 정확성이 높음
- **표본조사**는 여론조사나 마케팅 조사처럼 일부의 데이터를 분석하여 모집단을 추정하는 조사로 효율적이지만 대표성 확보가 중요함
- 실제 업무 환경에서는 시간과 비용 제약으로 표본조사를 주로 활용하며, 신뢰도 높은 표본을 얻는 것이 분석의 핵심임

### 2.3 표본추출 시의 다양한 편향과 해결방법

- 표본추출 편향: 표본이 모집단 특성을 대표하지 못하는 현상으로 무작위(random) 추출법으로 해결 가능
- 가구편향: 크고 작은 가구의 표본 추출 확률 차이로 발생하며, 층화추출(stratified sampling) 등으로 보완 가능
- 무응답편향: 설문에 응답한 사람과 하지 않은 사람 간의 차이로 발생하며, 응답률을 높이거나 후처리(weighting)를 통해 해결
- 응답편향(브래들리 효과): 응답자의 심리적 요인이나 사회적 기대에 의해 발생하는 편향으로 익명성 보장 등으로 완화 가능

### 03. 변수와 척도

### 3.1 변수의 종류에 대한 구체적 구분

- **범주형 변수Categorical Variables**
    - 명목형Nominal : 데이터의 순서가 없고 구분만 가능한 변수 (성별, 국적, 지역 등)
    - 순서형Ordinal : 범주 간 순서가 존재하며, 상대적인 서열을 나타내는 변수 (만족도, 등급, 성적 등)
- **연속형 변수Continuous Variables**
    - 간격척도Interval : 데이터 간 간격이 의미 있고, 절대적 원점이 존재하지 않음 (온도, IQ 점수 등)
    - 비율척도Ratio: 절대적 원점이 존재하여 비율계산이 가능하며, 나이, 키, 몸무게 등 수학적 계산이 용이한 변수

### 3.2 변수 간의 관계 분석 및 중요성

- 변수 관계를 분석하면 데이터 내 숨겨진 상관성과 인과관계를 밝혀낼 수 있으며, 독립변수(independent variable)와 종속변수(dependent variable)를 명확히 구분하는 것이 중요
- 상관관계 분석을 통해 두 변수의 연관성 강도와 방향성을 파악하고, 회귀분석 등을 통해 인과관계를 도출

### 04. 데이터의 기술 통계적 측정

### 4.1 중심성향(중심 경향) 측정법의 이해

- **평균mean**: 전체 데이터를 모두 합하여 데이터 개수로 나눈 값으로, 이상치에 민감하나 일반적으로 대표값으로 사용
- **중앙값median** : 데이터를 크기 순으로 나열했을 때 정중앙에 위치한 값으로, 이상치에 강건하여 극단값 존재 시 유용
- **최빈값mode**: 가장 많이 나타난 값으로, 범주형 데이터에서 유용하며 데이터 분포의 봉우리를 파악할 때 사용

### 4.2 산포도 측정 방법과 활용

- **분산variance** : 데이터가 평균에서 얼마나 떨어져 있는지의 제곱을 평균한 값으로 데이터의 퍼짐 정도 측정
- **표준편차standard deviation** : 분산의 제곱근으로 데이터가 평균을 기준으로 얼마나 퍼져 있는지 직관적으로 표현
- **범위range** : 데이터 최대값과 최소값 차이로 간단히 산포도 확인 가능
- **사분위수quartile** : 데이터를 4등분한 값으로 중앙집중성과 데이터의 분포 특성을 파악
- **변동계수CV** : 평균 대비 산포도의 크기를 상대적으로 나타내며, 서로 다른 스케일의 데이터를 비교할 때 유용

### 4.3 왜도와 첨도의 의미와 특징

- **왜도skewness** : 데이터의 좌우 비대칭성을 나타내며, 왜도가 0에 가까우면 좌우대칭, 양수면 오른쪽 꼬리가 긴 형태, 음수면 왼쪽 꼬리가 긴 형태
- **첨도kurtosis** : 분포의 뾰족한 정도로, 양수는 정규분포보다 뾰족한 분포(leptokurtic), 음수는 정규분포보다 평평한 분포(platykurtic)

### 05. 확률과 확률변수

### 5.1 확률의 기본적 이해

- 확률은 사건이 일어날 가능성을 0과 1 사이 숫자로 표현한 것으로, 확률이 0이면 절대 발생하지 않고, 1이면 반드시 발생함을 의미
- 확률은 빈도주의적 관점(실험 반복 횟수 대비 사건 발생 빈도)과 베이지안 관점(주관적 판단에 따른 사전확률과 사후확률 갱신)이 존재

### 5.2 확률의 종류와 예시

- 고전적 확률: 모든 사건이 발생할 가능성이 같다고 가정할 때 사용(동전던지기, 주사위 던지기 등)
- 경험적 확률: 실제 실험이나 관찰로 얻은 데이터를 바탕으로 추정된 확률(공장 품질 검사, 설문조사 응답률 등)
- 주관적 확률: 개인의 경험, 직관, 지식에 따라 정해진 확률로 불확실성이 높음(투자자의 예상 수익률 등)

### 5.3 분할법과 베이즈 이론의 활용 및 예시

- **분할법**: 복잡한 사건의 확률을 간단한 하위 사건으로 나누고, 하위 사건의 확률을 개별적으로 계산한 뒤 종합
- **베이즈 정리(Bayes’ theorem)**: 새로운 정보를 이용해 사건의 확률을 갱신하는 방법으로, 사전확률(prior), 우도(likelihood), 사후확률(posterior)을 활용하여 불확실성 속에서 합리적 판단

### 5.4 확률변수 개념과 특징

- 이산확률변수: 셀 수 있는 값으로 표현(동전 결과의 앞뒤, 주사위 숫자)
- 연속확률변수: 측정 가능한 연속적 값으로 표현(키, 몸무게, 시간, 온도 등)

### 5.5 심슨의 역설(Simpson’s paradox) 깊은 이해와 예시

- 부분집단의 분석 결과가 전체 분석 결과와 상반되는 현상으로, 데이터를 부분적으로 나눠 분석하지 않으면 잘못된 결론을 도출할 수 있음을 나타내는 역설
- 다양한 그룹의 데이터를 세부적으로 분석하고 결과를 해석할 때 주의가 필요함 (성별·연령별로 세부 분석 시 전체 평균과 다른 결과가 나타날 수 있음)

# 확인 문제

## 문제 1.

> 🧚Q. 한 대형 병원이 두 명의 외과 의사(A와 B)의 수술 성공률을 비교하려고 한다. 과거 1년간의 데이터를 보면, A 의사의 전체 수술 성공률은 80%, B 의사의 전체 수술 성공률은 90%였다. 이 데이터를 본 병원 경영진은 A 의사의 실력이 B 의사보다 별로라고 판단하여 A 의사의 수술 기회를 줄이는 방향으로 정책을 조정하려 한다.
그러나 일부 의료진은 이 결론에 의문을 제기했다.
그들은 “단순한 전체 성공률이 아니라 더 세부적인 데이터를 분석해야 한다”고 주장했다.
> 

> -A 의사의 실력이 실제로 B 의사보다 별로라고 결론짓는 것이 타당한가?
-그렇지 않다면, 추가로 확인해야 할 정보는 무엇인가?
> 

```
이는 심슨의 역설에 대한 전형적 사례 중 하나로, 현재 데이터만으로 A가 B보다 실력이 별로하고 하는 것은 타당하지 않다/ 수술 난이도별, 유형별 성공률을 드릴다운하여 비교해보아야 하고, 또한 양 의사 모두 성공률을 suppor하는 표본 개수가 충분해야 한다.
```

### 🎉 수고하셨습니다.