# ML 6주차 정규과제

📌ML 정규과제는 매주 정해진 **유튜브 강의 영상을 통해 머신러닝 이론을 학습**한 후, 해당 내용을 바탕으로 **실습 문제를 풀어보며 이해도를 높이는 학습 방식**입니다. 

이번주는 아래의 **ML_6th_TIL**에 명시된 유튜브 강의를 먼저 수강해 주세요. 학습 중에는 주요 개념을 스스로 정리하고, 이해가 어려운 부분은 강의 자료나 추가 자료를 참고해 보완해주세요. 과제까지 다 작성한 이후에 Github를 과제 시트에 제출해주시면 됩니다.



**(수행 인증샷은 필수입니다.)** 

> 주어진 과제를 다 한 이후, 인증샷이나 따로 코드를 깃허브에 정리하여 제출해주세요.



## ML_6th_TIL

### Principal Component Analysis(PCA, 주성분 분석)

<br>



## 주차별 학습 (Study Schedule)

| 주차  | 공부 범위                              | 완료 여부 |
| ----- | -------------------------------------- | --------- |
| 1주차 | 선형 회귀 (Linear Regression) (1)      | ✅         |
| 2주차 | 선형 회귀 (Linear Regression) (2)      | ✅         |
| 3주차 | 로지스틱 회귀 (Logistic Regression)    | ✅         |
| 4주차 | 결정 트리 (Decision Tree)              | ✅         |
| 5주차 | 앙상블 : 랜덤 포레스트 (Random Forest) | ✅         |
| 6주차 | 주성분 분석 (PCA)                      | ✅         |
| 7주차 | K - 평균 군집화                        | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리

## 01. Principal Component Analysis(PCA, 주성분 분석)

```
✅ 학습 목표 :
* PCA(주성분 분석)의 필요성과 목적을 이해할 수 있다.
* 변수 선택과 변수 추출의 차이를 이해하고, PCA가 변수 추출 방식임을 이해할 수 있다.
* PCA의 수학적 원리(공분산 행렬, 고유값/고유벡터, 사영)를 이해할 수 있다.
* PCA 알고리즘의 절차를 이해하고 설명할 수 있다.
* PCA의 한계와 대안 기법을 이해할 수 있다. 
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->



<br>
<br>

---

# 2️⃣ 과제

> **`Scikit-learn`의 손글씨 숫자(digits) 데이터셋을 로드합니다. 원본 데이터는 64개의 변수(8 X 8 픽셀)을 가집니다. PCA를 적용하여 데이터를 2개의 주성분으로 축소하고, 2차원 평면에 각 숫자가 어떻게 분포하는지 산점도로 시각화합니다. 첫 2개의 주성분이 전체 데이터 분산의 몇 %를 설명하는지 확인하고, 그 의미를 주피터 노트북에 서술하세요.**



~~~
과제 가이드
1. 데이터 로드
- from sklearn.datasets import load_digits 을 통해 불러오세요.

2. PCA 적용
- from sklearn.decomposition import PCA 라이브러리를 사용하시면 됩니다. 
- 예시) pca = PCA(n_components = k) 와 같이 사용하면 됩니다. 

3. 분석 설명
- print(f'PC1: {explained_var_ratio[0]:.2%}, PC2: {explained_var_ratio[1]:.2%}') 
- 첫 2개의 중성분이 전체 분산의 몇 %를 설명하는지 확인하기 

* 분석 포인트 
- 산점도를 해석하기 
- 분산 설명력을 해석하기 
	* PCA는 최대 분산 방향을 찾지만 분류 목적이 아닙니다. 
	* 고차원의 복잡한 구조를 단순화해서 보여주는 것입니다. 
~~~



<br>

### 🎉 수고하셨습니다.
